{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9918b76-cd03-4de7-a95b-a75576433954",
      "metadata": {
        "id": "a9918b76-cd03-4de7-a95b-a75576433954"
      },
      "source": [
        "# Inductive Node classification using GraphSAGE\n",
        "---  \n",
        "\n",
        "In this tutorial, we will use `Scikit-Network` [1] implementation of $\\texttt{GraphSAGE}$ [2], a Graph Neural Network model, to solve a node classification task on [wikivitals dataset](https://netset.telecom-paris.fr/pages/wikivitals.html).  \n",
        "\n",
        "The visualizations in this tutorial are built using [UMAP](https://umap-learn.readthedocs.io/en/latest/) [3] and [Plotly](https://plotly.com/graphing-libraries/).\n",
        "\n",
        "References:\n",
        "* [1] T. Bonald, N. de Lara, Q. Lutz, B. Charpentier (2020), [Scikit-network: Graph Analysis in Python](https://www.jmlr.org/papers/volume21/20-412/20-412.pdf)\n",
        "* [2] Hamilton, W. Ying, R., & Leskovec, J. (2017), [Inductive Representation Learning on Large Graphs.](https://arxiv.org/pdf/1706.02216.pdf)\n",
        "* [3] L. McInnes, J. Healy, J. Melville (2018), [Umap: Uniform manifold approximation and projection for dimension reduction.](https://arxiv.org/pdf/1802.03426.pdf?source=post_page---------------------------)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29557b40-ac0e-41ea-a58b-98e338e30333",
      "metadata": {
        "tags": [],
        "id": "29557b40-ac0e-41ea-a58b-98e338e30333"
      },
      "source": [
        "**Install and imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2ead1e-f158-470a-bf6f-5fdf627b5d29",
      "metadata": {
        "id": "4b2ead1e-f158-470a-bf6f-5fdf627b5d29"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.22\n",
        "!pip install scikit-network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d67eac-7ab2-4212-9b90-0e65e3028b26",
      "metadata": {
        "id": "47d67eac-7ab2-4212-9b90-0e65e3028b26"
      },
      "outputs": [],
      "source": [
        "from IPython.display import SVG\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sknetwork.classification import get_accuracy_score\n",
        "from sknetwork.data import load_netset\n",
        "from sknetwork.gnn import GNNClassifier\n",
        "from sknetwork.linalg.normalization import normalize\n",
        "from sknetwork.ranking.postprocess import top_k\n",
        "from sknetwork.utils import get_degrees\n",
        "from sknetwork.visualization import svg_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb42fd9-8a30-444f-a92e-18b0f6dfee24",
      "metadata": {
        "id": "ebb42fd9-8a30-444f-a92e-18b0f6dfee24"
      },
      "source": [
        "# 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be0926d2-d088-437a-9223-1958cea6083a",
      "metadata": {
        "id": "be0926d2-d088-437a-9223-1958cea6083a"
      },
      "source": [
        "### 1.1 GraphSAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b135d62-3cd8-4694-8fe8-5642f94e4840",
      "metadata": {
        "id": "8b135d62-3cd8-4694-8fe8-5642f94e4840"
      },
      "source": [
        "Recently, deep learning methods showed significant performance in prediction tasks in numerous research fields, including computer vision and natural language processing. **Graph Neural Network (GNN)** approaches have been specifically designed to take advantage of these great performances while applying them to graphs.  \n",
        "One of these methods, $\\texttt{GraphSAGE}$, has been created to generalize well to **unseen nodes**, in an *inductive* manner. The approach relies on a context-based similarity assumption, which states that nodes in the same neighborhood are similar and thus should be close in the embedding space. In addition to the aggregation scheme developed in previous GNN methods, $\\texttt{GraphSAGE}$ also includes a **sampling** module which allows to reduce the computation time of the learning process. \n",
        "\n",
        "The embedding generation process for a graph $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$ works as follows: at each layer $k$, we (i) aggregate information from node's $v \\in \\mathcal{V}$ neighborhood $\\mathcal{N}(v)$, using $\\texttt{AGGREGATE}$ function (e.g mean) to produce the neighborhood representation of node's $v$, $h^{k}_{\\mathcal{N}(v)}$ and (ii) use $\\texttt{CONCAT}$ function (e.g concatenation or sum in practice) on both the neighborhood representation $h^{k}_{\\mathcal{N}(v)}$ and the node's previous representation $h^{k-1}_v$ to produce the final embedding of node $v$, $h^{k}_v$.\n",
        "\n",
        "$$\n",
        "h^{k}_{\\mathcal{N}(v)} \\leftarrow \\text{AGGREGATE}_k(\\{h_{u}^{k-1}, \\forall{u} \\in \\mathcal{N}(v)\\}) \\\\\n",
        "h^{k}_{v} \\leftarrow \\sigma \\biggl(W^{k} \\cdot \\text{CONCAT}\\big(h^{k-1}_v, h^{k}_{\\mathcal{N}(v)}\\big) \\biggl)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3fc9319",
      "metadata": {
        "id": "f3fc9319"
      },
      "source": [
        "Such a model can be trained specifically on a downstream machine learning task, such as node classification, by using a loss function which enforces similar nodes to be close in the embedding space, and non-similar nodes to be set further appart.  \n",
        "\n",
        "Note: Different aggregators are used in [2] (`mean`, `LSTM`, `MaxPooling`). In this tutorial, we will use the `mean` aggregator."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9566838d-67ae-443a-abab-69db39d6085d",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "9566838d-67ae-443a-abab-69db39d6085d"
      },
      "source": [
        "### 1.2 Scikit-network and sparse formats  \n",
        "\n",
        "Scikit-network is a Python package for the analysis of large graphs. For this purpose, it uses memory-efficient representation of graphs as sparse matrices in [CSR](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)  (Compressed Sparse Row) format.  \n",
        "Let's see how this format works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c67f99-0fdf-437e-9f59-81847091b104",
      "metadata": {
        "id": "75c67f99-0fdf-437e-9f59-81847091b104"
      },
      "outputs": [],
      "source": [
        "# Random matrix (dense format)\n",
        "X_dense = np.random.randint(3, size = (10,5))\n",
        "X_dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f524a1f0-495b-4aea-ba77-9a626b9baa7a",
      "metadata": {
        "id": "f524a1f0-495b-4aea-ba77-9a626b9baa7a"
      },
      "outputs": [],
      "source": [
        "# Convert to sparse CSR format\n",
        "X_csr = sparse.csr_matrix(X_dense)\n",
        "X_csr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b39459b",
      "metadata": {
        "id": "7b39459b"
      },
      "source": [
        "Our matrix is now in CSR format. We can get useful information about it using specific parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f1b0c3-89bc-4fdc-993d-303d4333d8d8",
      "metadata": {
        "id": "28f1b0c3-89bc-4fdc-993d-303d4333d8d8"
      },
      "outputs": [],
      "source": [
        "X_csr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b3b2d6c-7e97-4c47-ba35-38f5b55964e0",
      "metadata": {
        "id": "4b3b2d6c-7e97-4c47-ba35-38f5b55964e0"
      },
      "outputs": [],
      "source": [
        "# Number of non-zero values\n",
        "X_csr.nnz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e534af9a-fa2b-4838-81b4-cd5c53e2b52b",
      "metadata": {
        "id": "e534af9a-fa2b-4838-81b4-cd5c53e2b52b"
      },
      "source": [
        "Our matrix is stored as 3 arrays accessible as parameters of the CSR matrix: \n",
        "* `indices`: array of column indices\n",
        "* `data`: array of corresponding non-zero values\n",
        "* `indptr`: points to row starts in `indices` and `data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880b78fc-9717-4c32-8ed9-219bd4918308",
      "metadata": {
        "id": "880b78fc-9717-4c32-8ed9-219bd4918308"
      },
      "outputs": [],
      "source": [
        "X_csr.indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb63bd8-823e-4f3b-8c15-20a6359302f9",
      "metadata": {
        "id": "8eb63bd8-823e-4f3b-8c15-20a6359302f9"
      },
      "outputs": [],
      "source": [
        "X_csr.indptr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe9eb584-ed30-4f6e-b92f-7f2656c83e27",
      "metadata": {
        "id": "fe9eb584-ed30-4f6e-b92f-7f2656c83e27"
      },
      "outputs": [],
      "source": [
        "X_csr.data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49629250-afdc-4591-b8be-7f47c9cbe74c",
      "metadata": {
        "id": "49629250-afdc-4591-b8be-7f47c9cbe74c"
      },
      "source": [
        "# 2. Node classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "193bebcc",
      "metadata": {
        "id": "193bebcc"
      },
      "source": [
        "In node classification task, the goal is to predict the categorical label of nodes in a graph. For this purpose, we can use deep-learning based graph models, such as $\\texttt{GraphSAGE}$, to convert high-dimensional objects into low-dimensional latent space, then use these learned representations to predict the belonging class of each node."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4dc308d-eca4-4176-ac36-dd2efcb38464",
      "metadata": {
        "tags": [],
        "id": "e4dc308d-eca4-4176-ac36-dd2efcb38464"
      },
      "source": [
        "## 2.1 Data: `wikivitals`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a50b240-6023-4c99-b121-f5ce3b53665d",
      "metadata": {
        "id": "3a50b240-6023-4c99-b121-f5ce3b53665d"
      },
      "source": [
        "[Wikivitals](https://netset.telecom-paris.fr/pages/wikivitals.html) contains Wikipedia vitals articles. In this dataset, each node is a Wikipedia article and a directed edge exists between two nodes if one article is citing the other. Each node comes with a feature vector which consists of the words used in its summary, as well as a category (e.g 'Mathematics', 'People', etc.). Features are represented in a bag-of-words format, where the $i^{th}$ element of the feature vector contains the number of occurences of the $i^{th}$ word of a vocabulary in the article.\n",
        "\n",
        "In summary, `wikivitals` dataset contains:\n",
        "* 10011 articles, with 824999 links between them\n",
        "* 37845 distinct words and 1363301 links between articles and words\n",
        "* 11 distinct labels \n",
        "\n",
        "The goal is to predict the category of each node in the graph, using both the structural and feature information we got."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b6432ce",
      "metadata": {
        "id": "6b6432ce"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "graph = load_netset('wikivitals')\n",
        "adjacency = graph.adjacency # graph of articles\n",
        "features = graph.biadjacency # graph of articles*words\n",
        "names = graph.names # article names\n",
        "names_features = graph.names_col # word names\n",
        "names_labels = graph.names_labels # category names\n",
        "labels = graph.labels # categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bf91b4",
      "metadata": {
        "id": "76bf91b4"
      },
      "outputs": [],
      "source": [
        "# Names of labels to predict\n",
        "names_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b973e63f-b0d8-433e-9eca-da1e79782bed",
      "metadata": {
        "id": "b973e63f-b0d8-433e-9eca-da1e79782bed"
      },
      "outputs": [],
      "source": [
        "# Number of distincty labels\n",
        "n_labels = len(names_labels)\n",
        "n_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215f5dc7-9a63-464a-b9e7-52fe3cb80771",
      "metadata": {
        "id": "215f5dc7-9a63-464a-b9e7-52fe3cb80771"
      },
      "outputs": [],
      "source": [
        "# Adjacency matrix of the graph, i.e graph of articles\n",
        "adjacency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d94531-aa9a-4297-af85-ac0f9e02ee07",
      "metadata": {
        "id": "f2d94531-aa9a-4297-af85-ac0f9e02ee07"
      },
      "outputs": [],
      "source": [
        "# 10 random article names\n",
        "np.random.choice(names, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfa3da2-3494-40e4-97ec-88570e90896b",
      "metadata": {
        "id": "dcfa3da2-3494-40e4-97ec-88570e90896b"
      },
      "outputs": [],
      "source": [
        "# Features of the nodes, i.e bags-of-words\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12b6c75-8e59-4f6f-9f72-e8c188d18de3",
      "metadata": {
        "id": "c12b6c75-8e59-4f6f-9f72-e8c188d18de3"
      },
      "outputs": [],
      "source": [
        "# Information about a specific article\n",
        "i = np.random.choice(adjacency.shape[0])\n",
        "\n",
        "print(f'Article: {names[i]} - Category: {names_labels[labels[i]]}')\n",
        "words = names_features[features[i].indices]\n",
        "\n",
        "if len(words) > 15:\n",
        "    words = np.random.choice(words, 15)\n",
        "print(f'Random words: {words}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0bba223-ecae-4c4c-b635-722e88c2fad7",
      "metadata": {
        "tags": [],
        "id": "e0bba223-ecae-4c4c-b635-722e88c2fad7"
      },
      "source": [
        "## 2.2 Model: GraphSAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e369949-df9b-41e0-8971-6c7b6309883a",
      "metadata": {
        "id": "7e369949-df9b-41e0-8971-6c7b6309883a"
      },
      "source": [
        "### 2.2.1 Predictions without training  \n",
        "\n",
        "We will use the `GNNClassifier` object to initialize our model using $\\texttt{GraphSAGE}$ layers. For this purpose, we define:\n",
        "* dimensions for hidden and output layer\n",
        "* layer type \n",
        "* activation functions \n",
        "* sample sizes parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "438cee7f-6841-4fd0-aae0-1ccb1255831a",
      "metadata": {
        "id": "438cee7f-6841-4fd0-aae0-1ccb1255831a"
      },
      "outputs": [],
      "source": [
        "# GNN classifier with a single hidden layer\n",
        "hidden_dim = 32\n",
        "\n",
        "gnn = GNNClassifier(dims=[hidden_dim, n_labels],\n",
        "                    layer_types='graphsage',\n",
        "                    activations=['Relu', 'Softmax'],\n",
        "                    sample_sizes=[25, 10],\n",
        "                    verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1014b997-c9cd-404b-835b-2ae80e93e245",
      "metadata": {
        "id": "1014b997-c9cd-404b-835b-2ae80e93e245"
      },
      "outputs": [],
      "source": [
        "print(gnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4be3b1db",
      "metadata": {
        "id": "4be3b1db"
      },
      "source": [
        "Before training the model, let's use it as an encoder (without training) to create embeddings for each node in our graph. We use the `forward()` method with adjacency and feature matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c301aba3-1a0e-43f4-9109-2fe027191247",
      "metadata": {
        "id": "c301aba3-1a0e-43f4-9109-2fe027191247"
      },
      "outputs": [],
      "source": [
        "# Weights randomly initialized - no training\n",
        "output_no_training = gnn.forward(adjacency, features)\n",
        "\n",
        "# Predictions - no training\n",
        "labels_no_training = np.argmax(output_no_training, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e643c8-1e86-4f33-90d8-c4f5bccecb78",
      "metadata": {
        "id": "c9e643c8-1e86-4f33-90d8-c4f5bccecb78"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "accuracy_without_training = get_accuracy_score(labels, labels_no_training)\n",
        "print(f'Accuracy without training: {accuracy_without_training:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0265fe6a-de50-4401-ab3b-553b3af0db03",
      "metadata": {
        "id": "0265fe6a-de50-4401-ab3b-553b3af0db03"
      },
      "source": [
        "What happens under the hood?  \n",
        "* Shapes of parameters $W$ and $b$\n",
        "* Shape of embedding and outputs for each layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "142354e7-6afb-4091-8890-e83d256e949a",
      "metadata": {
        "id": "142354e7-6afb-4091-8890-e83d256e949a"
      },
      "outputs": [],
      "source": [
        "for i, l in enumerate(gnn.layers):\n",
        "    print(f'Layer {i} | Weights: {l.weight.shape} - bias: {l.bias.shape} - embedding: {l.embedding.shape} - output: {l.output.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b535ae3-8de4-4b5d-827c-8e6600848824",
      "metadata": {
        "id": "6b535ae3-8de4-4b5d-827c-8e6600848824"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1154f2b9",
      "metadata": {
        "id": "1154f2b9"
      },
      "outputs": [],
      "source": [
        "!pip install pandas scikit-learn numba tqdm pynndescent matplotlib datashader holoviews \n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc34594",
      "metadata": {
        "id": "4dc34594"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import umap\n",
        "import umap.plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feafa960-a9eb-410b-b787-1b6e524cdd14",
      "metadata": {
        "id": "feafa960-a9eb-410b-b787-1b6e524cdd14"
      },
      "outputs": [],
      "source": [
        "# Static 2d visualization\n",
        "mapper = umap.UMAP().fit(gnn.layers[1].embedding)\n",
        "umap.plot.points(mapper, labels=names_labels[labels]);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd3dc81a-db0e-4bd5-bff3-3a3c51d6e805",
      "metadata": {
        "id": "fd3dc81a-db0e-4bd5-bff3-3a3c51d6e805"
      },
      "source": [
        "### 2.2.2 Predictions with supervised learning  \n",
        "\n",
        "We can now train our GNN model using the previously initialized object. We split our data using train/val/test subgraphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafe52fb-0540-4c57-9b41-67e7f7d5d36b",
      "metadata": {
        "id": "eafe52fb-0540-4c57-9b41-67e7f7d5d36b"
      },
      "outputs": [],
      "source": [
        "labels_pred = gnn.fit_predict(adjacency, features, labels, \n",
        "                              train_size=0.8, val_size=0.1, test_size=0.1, \n",
        "                              history=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9aab6a-e532-43f9-b9b2-0af0322b17ee",
      "metadata": {
        "id": "aa9aab6a-e532-43f9-b9b2-0af0322b17ee"
      },
      "source": [
        "Now that the GNN model is trained, we have access to the full history of training information saved in `history_` parameter, as well as model a summary of results stored in parameters:\n",
        "* `embedding_`: last nodes embedding\n",
        "* `output_`: predicted probabilities for each class\n",
        "* `labels_`: predicted node labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e06b78b9-3a43-4201-8d73-a0e1e456653f",
      "metadata": {
        "id": "e06b78b9-3a43-4201-8d73-a0e1e456653f"
      },
      "outputs": [],
      "source": [
        "gnn.history_.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670f3375",
      "metadata": {
        "id": "670f3375"
      },
      "outputs": [],
      "source": [
        "print(f'Node embedding: {gnn.embedding_.shape}')\n",
        "gnn.embedding_[0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85655103",
      "metadata": {
        "id": "85655103"
      },
      "outputs": [],
      "source": [
        "# Predicted probabilities for each class\n",
        "print(gnn.output_[1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f257cb",
      "metadata": {
        "id": "a5f257cb"
      },
      "outputs": [],
      "source": [
        "# Predicted labels\n",
        "gnn.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb90c883-50f8-4474-a259-92b73d252ff7",
      "metadata": {
        "id": "eb90c883-50f8-4474-a259-92b73d252ff7"
      },
      "outputs": [],
      "source": [
        "# plot learning information\n",
        "fig, ax = plt.subplots(1, 2, figsize=(7, 4))\n",
        "ax[0].plot(gnn.history_.get('loss'), label='Loss')\n",
        "ax[1].plot(gnn.history_.get('train_accuracy'), label='train accuracy')\n",
        "ax[1].plot(gnn.history_.get('val_accuracy'), label='val accuracy')\n",
        "for i in range(2):\n",
        "    ax[i].set_xlabel('# epochs')\n",
        "    ax[i].legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c15809-56e7-4fcd-8204-aecb4e96088b",
      "metadata": {
        "id": "46c15809-56e7-4fcd-8204-aecb4e96088b"
      },
      "outputs": [],
      "source": [
        "# Accuracy on test set\n",
        "test_mask = gnn.test_mask\n",
        "get_accuracy_score(labels[test_mask], labels_pred[test_mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392366af-a20d-42ae-97b0-596a43d31127",
      "metadata": {
        "id": "392366af-a20d-42ae-97b0-596a43d31127"
      },
      "outputs": [],
      "source": [
        "# Explore mis-predicted nodes\n",
        "mispreds = labels != labels_pred\n",
        "\n",
        "for i in names[mispreds][-5:]:\n",
        "    idx = np.where(names == i)[0][0]\n",
        "    print(f'{i}')\n",
        "    print(f'    True label: {names_labels[labels[idx]]:} - predicted label: {names_labels[labels_pred[idx]]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3eddca5",
      "metadata": {
        "id": "b3eddca5"
      },
      "source": [
        "**Todo:**\n",
        "* List the 20 closest articles to the category **'Mathematics'** in terms of cosine similarity in the embedding space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd013c90",
      "metadata": {
        "id": "bd013c90"
      },
      "outputs": [],
      "source": [
        "# Todo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c000a3ad",
      "metadata": {
        "id": "c000a3ad"
      },
      "source": [
        "**Visualization**  \n",
        "\n",
        "We use [UMAP library](https://umap-learn.readthedocs.io/en/latest/) (Uniform Manifold Approximation and Projection for Dimension Reduction) and [Plotly]() to plot our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86cbcf69",
      "metadata": {
        "id": "86cbcf69"
      },
      "outputs": [],
      "source": [
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adef247f",
      "metadata": {
        "id": "adef247f"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "from plotly import offline\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28502829",
      "metadata": {
        "id": "28502829"
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "   \n",
        "def build_df(graph, embedding, labels_pred, node_type='article', mask=None):\n",
        "    \"\"\" Build DataFrame from graph data, node embedding and predicted labels \"\"\"\n",
        "    \n",
        "    n = graph.adjacency.shape[0]\n",
        "    \n",
        "    # Select 5 features randomly\n",
        "    words_sel = [graph.names_col[np.random.choice(graph.biadjacency[i].indices, 5)] for i in range(n)]\n",
        "\n",
        "    # Get coordinates and attributes\n",
        "    df_coord = pd.DataFrame(embedding, columns=['X', 'Y', 'Z'])\n",
        "    if node_type == 'article':\n",
        "        df_qual = pd.DataFrame({'Article': graph.names, \n",
        "                                'Label': graph.names_labels[graph.labels], \n",
        "                                'Predicted label': graph.names_labels[labels_pred],\n",
        "                                'Words': words_sel})\n",
        "        df = pd.concat((df_coord, df_qual), axis=1)\n",
        "\n",
        "        # Size of marker according to accuracy of category\n",
        "        unique_labels, counts = np.unique(graph.labels, return_counts=True)\n",
        "        for lab, c in zip(unique_labels, counts):\n",
        "            acc = np.sum(labels_pred[graph.labels == lab] == lab) / c\n",
        "            df.loc[df['Label'] == graph.names_labels[lab], 'group acc'] = round(acc, 3)\n",
        "    elif node_type == 'word':\n",
        "        df_qual = pd.DataFrame({'Word': graph.names_col[mask], \n",
        "                                'Predicted label': graph.names_labels[labels_pred]})\n",
        "        df = pd.concat((df_coord, df_qual), axis=1)\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f509a3b",
      "metadata": {
        "id": "4f509a3b"
      },
      "outputs": [],
      "source": [
        "# Static 2d visualization\n",
        "mapper = umap.UMAP(n_components=2).fit(gnn.embedding_)\n",
        "umap.plot.points(mapper, labels=names_labels[labels]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bab1983",
      "metadata": {
        "id": "7bab1983"
      },
      "outputs": [],
      "source": [
        "# 3d interactive using Plotly\n",
        "size = 800\n",
        "\n",
        "# Dimension reduction of GNN embedding using UMAP\n",
        "labels_unique, counts = np.unique(labels, return_counts=True)\n",
        "umap_emb = umap.UMAP(n_components=3).fit_transform(gnn.embedding_)\n",
        "\n",
        "df = build_df(graph, umap_emb, labels_pred)\n",
        "fig = px.scatter_3d(df, x='X', y='Y', z='Z', opacity=0.6, color='Label', \n",
        "                    hover_data={'X': False, 'Y':False, 'Z': False, 'group acc': True, \n",
        "                                'Article':True, 'Label': True, 'Predicted label': True, 'Words': True}, \n",
        "                    width=size*1.2, height=size, color_discrete_sequence=px.colors.qualitative.G10)\n",
        "\n",
        "fig.update_traces(marker=dict(size=3, line=dict(width=0)))\n",
        "fig.show()\n",
        "#plotly.offline.plot(fig, filename='wikivitals_3d_embedding.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2147da",
      "metadata": {
        "id": "7a2147da"
      },
      "source": [
        "### 2.2.3 What if we remove features?  \n",
        "\n",
        "We can try to learn node embeddings by setting **random features** and keep only the graph structure as input, in order to get a deeper insight of their importance in the learning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98eb4e6c",
      "metadata": {
        "id": "98eb4e6c"
      },
      "outputs": [],
      "source": [
        "# Initialize random features\n",
        "rand_features = sparse.random(features.shape[0], features.shape[1]).tocsr()\n",
        "rand_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "317bce7a",
      "metadata": {
        "id": "317bce7a"
      },
      "outputs": [],
      "source": [
        "# GNN classifier with a single hidden layer\n",
        "hidden_dim = 16\n",
        "\n",
        "gnn_rand_feat = GNNClassifier(dims=[hidden_dim, n_labels],\n",
        "                    layer_types='graphsage',\n",
        "                    activations=['Relu', 'Softmax'],\n",
        "                    sample_sizes=[25, 10],\n",
        "                    verbose=True)\n",
        "\n",
        "labels_pred_rand_feat = gnn_rand_feat.fit_predict(adjacency, rand_features, labels, \n",
        "                              train_size=0.8, val_size=0.1, test_size=0.1, \n",
        "                              history=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa99bc7",
      "metadata": {
        "id": "afa99bc7"
      },
      "outputs": [],
      "source": [
        "# Accuracy on test set\n",
        "test_mask = gnn_rand_feat.test_mask\n",
        "get_accuracy_score(labels[test_mask], labels_pred_rand_feat[test_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5030fe37",
      "metadata": {
        "id": "5030fe37"
      },
      "source": [
        "### 2.2.4 What if we remove links between articles?  \n",
        "\n",
        "In the same manner, we can remove all edges between articles and train the model only using features to understand the importance of the structure of the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d209801d",
      "metadata": {
        "id": "d209801d"
      },
      "outputs": [],
      "source": [
        "# Adjacency matrix is the identity matrix\n",
        "identity_adjacency = sparse.identity(adjacency.shape[0]).tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236934d9",
      "metadata": {
        "id": "236934d9"
      },
      "outputs": [],
      "source": [
        "# GNN classifier with a single hidden layer\n",
        "hidden_dim = 16\n",
        "\n",
        "\n",
        "gnn_id_adj = GNNClassifier(dims=[hidden_dim, n_labels],\n",
        "                    layer_types='graphsage',\n",
        "                    activations=['Relu', 'Softmax'],\n",
        "                    sample_sizes=[25, 10],\n",
        "                    verbose=True)\n",
        "\n",
        "labels_pred_id_adj = gnn_id_adj.fit_predict(identity_adjacency, features, labels, \n",
        "                              train_size=0.8, val_size=0.1, test_size=0.1, \n",
        "                              history=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49835a9c",
      "metadata": {
        "id": "49835a9c"
      },
      "outputs": [],
      "source": [
        "# Accuracy on test set\n",
        "test_mask = gnn_id_adj.test_mask\n",
        "get_accuracy_score(labels[test_mask], labels_pred_id_adj[test_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14506461-179a-40a9-85de-0aed94e18a38",
      "metadata": {
        "id": "14506461-179a-40a9-85de-0aed94e18a38"
      },
      "source": [
        "# 3 Inductive predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdbc1bcb",
      "metadata": {
        "id": "bdbc1bcb"
      },
      "source": [
        "## 3.1 New article "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81e55c8",
      "metadata": {
        "id": "b81e55c8"
      },
      "outputs": [],
      "source": [
        "# Utility function\n",
        "\n",
        "def plot_new_article(graph, df, labels_pred, categories):\n",
        "    \"\"\"Plot article embedding, with new article highlighted.\"\"\"\n",
        "    \n",
        "    traces = []\n",
        "    colors = px.colors.qualitative.Alphabet \n",
        "\n",
        "    df['norm op'] = df['group acc'].apply(\n",
        "                        lambda x: (x - np.min(df['group acc'])) / (np.max(df['group acc']) - np.min(df['group acc'])))\n",
        "\n",
        "    n_labels = len(graph.names_labels)\n",
        "    for lab in range(n_labels):\n",
        "        sub_df = df[df['Label']==graph.names_labels[lab]]\n",
        "        traces.append(go.Scatter3d(\n",
        "                x = sub_df.X,\n",
        "                y = sub_df.Y,\n",
        "                z = sub_df.Z,\n",
        "                name = graph.names_labels[lab],\n",
        "                mode = 'markers',\n",
        "                opacity = np.clip(np.array(sub_df['norm op'].values[0]), 0.1, 0.9), \n",
        "                marker = dict(size=3, line=dict(width=0), color=colors[lab]),\n",
        "                text = sub_df['Article'],\n",
        "                customdata = sub_df['Predicted label'],\n",
        "                hovertemplate =\n",
        "                    \"<br>Article: %{text}<br>\" +\n",
        "                    f\"<br>Label: {graph.names_labels[lab]}<br>\" +\n",
        "                    \"<br>Pred label: %{customdata}<br>\" + \n",
        "                    f\"<br>Category acc: {sub_df['group acc'].unique()[0]}<br>\"\n",
        "                    \"<extra></extra>\"\n",
        "                )\n",
        "        )\n",
        "    traces.append(go.Scatter3d(\n",
        "        x = [df.iloc[-1].X],\n",
        "        y = [df.iloc[-1].Y],\n",
        "        z = [df.iloc[-1].Z],\n",
        "        name = 'New article',\n",
        "        marker = dict(size=10, line=dict(width=1)),\n",
        "        customdata = graph.names_labels[labels_pred],\n",
        "        hovertemplate =\n",
        "                    \"<br>Article: New Article<br>\" +\n",
        "                    f\"<br>Label: {graph.names_labels[categories]}<br>\" +\n",
        "                    \"<br>Pred label: %{customdata}<br>\"\n",
        "                    \"<extra></extra>\"\n",
        "\n",
        "    ))\n",
        "\n",
        "    layout = go.Layout(\n",
        "        title='Wikivitals embedding',\n",
        "        width=1000,\n",
        "        height=800,\n",
        "        autosize=False,\n",
        "    )\n",
        "\n",
        "    fig = dict(data=traces, layout=layout)\n",
        "\n",
        "    offline.iplot(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b13a15d",
      "metadata": {
        "id": "9b13a15d"
      },
      "source": [
        "### 3.1.1 Using only words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03673a2c",
      "metadata": {
        "id": "03673a2c"
      },
      "source": [
        "We can use our pre-trained GNN to predict the category of a new incoming article, using only the words in its summary. For this, we create a new article without any link to existing articles. Then, we create the summary of this article by selecting random words in dedicated categories. Our goal is to recover the category of the node, by feeding it to the forward method of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06206f4e",
      "metadata": {
        "id": "06206f4e"
      },
      "outputs": [],
      "source": [
        "# Select category\n",
        "category_idx = [10]\n",
        "print(f'Category: {names_labels[category_idx]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d2b1c6",
      "metadata": {
        "id": "d6d2b1c6"
      },
      "outputs": [],
      "source": [
        "keywords = []\n",
        "\n",
        "# Select 50 random words from articles in category\n",
        "for lab_idx in category_idx:\n",
        "    mask = labels == lab_idx\n",
        "    words_idx = np.flatnonzero(get_degrees(features[mask, :], transpose=True))\n",
        "    keywords_lab = np.random.choice(words_idx, int(np.round(50 / len(category_idx))))\n",
        "    keywords += list(keywords_lab)\n",
        "    \n",
        "keywords = np.array(keywords)\n",
        "print(f'Words in new articles: {names_features[keywords]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8fe00d0",
      "metadata": {
        "id": "d8fe00d0"
      },
      "outputs": [],
      "source": [
        "# Build new article using selected words\n",
        "new_features = np.zeros(features.shape[1], dtype=bool)\n",
        "new_features[keywords] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d400db4",
      "metadata": {
        "id": "1d400db4"
      },
      "outputs": [],
      "source": [
        "# Predict label of new article\n",
        "labels_pred_new_article = gnn.predict(None, new_features.reshape(1, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708fff39",
      "metadata": {
        "id": "708fff39"
      },
      "outputs": [],
      "source": [
        "print(f'Predicted category for new article: {names_labels[labels_pred_new_article]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44f8c39",
      "metadata": {
        "id": "a44f8c39"
      },
      "outputs": [],
      "source": [
        "# Most similar articles\n",
        "norm_embedding = normalize(gnn.embedding_, p=2)\n",
        "new_norm_embedding = normalize(gnn.layers[-1].embedding, p=2) \n",
        "\n",
        "similarities = norm_embedding.dot(new_norm_embedding.T)\n",
        "print(names[top_k(similarities.ravel(), 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4a0266",
      "metadata": {
        "id": "0f4a0266"
      },
      "source": [
        "**Visualize new article embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f3628a",
      "metadata": {
        "id": "01f3628a"
      },
      "outputs": [],
      "source": [
        "# UMAP embedding including new article\n",
        "new_emb = np.concatenate((gnn.embedding_, gnn.layers[-1].embedding), axis=0)\n",
        "new_umap_emb = umap.UMAP(n_components=3).fit_transform(new_emb)\n",
        "\n",
        "# DataFrame\n",
        "new_df = build_df(graph, new_umap_emb, labels_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a1da97",
      "metadata": {
        "id": "d3a1da97"
      },
      "outputs": [],
      "source": [
        "plot_new_article(graph, new_df, labels_pred_new_article, category_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86308f4",
      "metadata": {
        "id": "e86308f4"
      },
      "source": [
        "### 3.1.2 Using only references"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f1e073",
      "metadata": {
        "id": "57f1e073"
      },
      "source": [
        "Finally, we can create a new **empty article**, i.e an article without any word in its summary, by defining only its neighborhood through the relations with other similar articles. Again, the goal is to predict the category of the article using our pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649c4c60",
      "metadata": {
        "id": "649c4c60"
      },
      "outputs": [],
      "source": [
        "category_idx = 8\n",
        "n_nodes = 10 # number of neighbors for our new empty article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f80cf3",
      "metadata": {
        "id": "55f80cf3"
      },
      "outputs": [],
      "source": [
        "# Select n_nodes nodes in a category\n",
        "rand_articles = np.random.choice(np.flatnonzero([labels == category_idx]), n_nodes)\n",
        "print(f'Selected articles in category {names_labels[category_idx]}: {names[rand_articles]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27dd7fd4",
      "metadata": {
        "id": "27dd7fd4"
      },
      "outputs": [],
      "source": [
        "n = adjacency.shape[1]\n",
        "\n",
        "# Connect empty article with its neighbors\n",
        "adjacency_vector = sparse.csr_matrix((np.ones(n_nodes), (np.zeros(n_nodes), rand_articles)), \n",
        "                                     shape=(1, n))\n",
        "\n",
        "# new adjacency (with outgoing links from the new node)\n",
        "adjacency_new = sparse.vstack((adjacency, adjacency_vector))\n",
        "adjacency_new = sparse.hstack((adjacency_new, sparse.csr_matrix((n + 1, 1)))).tocsr()\n",
        "\n",
        "# new features (null features for the new node)\n",
        "features_new = sparse.vstack((features, sparse.csr_matrix((1, len(names_features)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2bd45e",
      "metadata": {
        "id": "cd2bd45e"
      },
      "outputs": [],
      "source": [
        "# Filter adjacency on new article and neighbors\n",
        "adjacency_vector_neighbs = np.concatenate((rand_articles, np.array([n])))\n",
        "adjacency_neighbs = adjacency_new[adjacency_vector_neighbs, :][:, adjacency_vector_neighbs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6f526e",
      "metadata": {
        "id": "4e6f526e"
      },
      "outputs": [],
      "source": [
        "# Visualize our new empty article and its neighborhood\n",
        "SVG(svg_graph(adjacency_neighbs, \n",
        "              names=np.hstack((names[rand_articles], np.array(['Empty article']))), \n",
        "              labels=np.hstack((labels[rand_articles], np.array([n_labels + 1])))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0c5a6d",
      "metadata": {
        "id": "5f0c5a6d"
      },
      "outputs": [],
      "source": [
        "# Label prediction\n",
        "labels_new = gnn.predict(adjacency_new, features_new)\n",
        "\n",
        "print(f'Label of neighbor nodes: {names_labels[category_idx]}')\n",
        "print(f'Predicted label: {names_labels[labels_new[-1]]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "499294a6",
      "metadata": {
        "id": "499294a6"
      },
      "outputs": [],
      "source": [
        "# UMAP embedding including new article\n",
        "new_emb = np.concatenate((gnn.embedding_, gnn.layers[-1].embedding), axis=0)\n",
        "new_umap_emb = umap.UMAP(n_components=3).fit_transform(new_emb)\n",
        "\n",
        "# DataFrame\n",
        "new_df = build_df(graph, new_umap_emb, labels_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a97f29e",
      "metadata": {
        "id": "1a97f29e"
      },
      "outputs": [],
      "source": [
        "plot_new_article(graph, new_df, [labels_new[-1]], category_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6261a5",
      "metadata": {
        "id": "4d6261a5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "readingGroupGNN",
      "language": "python",
      "name": "readinggroupgnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}