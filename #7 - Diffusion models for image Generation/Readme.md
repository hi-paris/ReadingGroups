## Edition 7 - Diffusion Models for Image Generation

➡️ For the seventh edition of the Hi! PARIS Reading groups, we teach you the generation of Images using Diffusion Models.

This reading group is devoted to recent diffusion models for image generation. These generative models are based on latent random variables and aim at sampling from highly complex probabilities distributions via a sequence of distributions which transform noise into the distribution of the data. They have many applications in image processing such as image denoising, inpainting, super resolution or image generation.  Through three recent papers, we will review the principle of these generative models, how to train them and some challenges related to particular applications.

The edition consists on 4 sessions.
The reading group will present some recent models and their application to the classification of molecules (session 1) and Wikipedia articles (session 2). 

### Session 1/4 – Generative modeling by estimating gradients of the data distribution – Denoising Diffusion Implicit Models
Tuesday 4 February, 2024 – 2.00-3.30pm (Online)


**📣 Speakers**

* Gabriel Cardoso, École polytechnique – IP Paris 


**📚 Program**

In this talk we will consider two of the first papers of what is now called Score based generative model. We will begin by “Generative modeling by estimating gradients of the data distribution.”, where for the first time the idea of sampling backwards from a sequence of diffused versions of the data is explored and that for the first time beat GAN’s in image generation tasks. We then will look at DDIM (Denoising Diffusion Implicit Models), which is a much more efficient sampler to sample backward from the same sequence of diffused distributions. We will compare the tradeoff obtained by sampling from the two algorithms.


**📑 Papers**

– NCSN: Song, Y., & Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32.\
– DDIM: Song, J., Meng, C., & Ermon, S. (2020, October). Denoising Diffusion Implicit Models. In International Conference on Learning Representations 

**🐍 Presentatin/Notebook/simulations**

– see above


### Session 2/4 – Score-Based Generative Modeling through Stochastic Differential Equations Zero-shot spatial layout conditioning for text-to-image diffusion models
Tuesday 12 March, 2024 – 2.00-3.30pm (Online)

